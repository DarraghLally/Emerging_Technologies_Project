{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emerging Technologies Project 2020\n",
    "***\n",
    "#### Trained Model\n",
    "\n",
    "1. This notebook should train a model to predict power output from wind speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "import pandas as pd\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Machine learning\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://keras.io/examples/vision/mnist_convnet/\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From video 'Neuron in Keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks.\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "# Numerical arrays\n",
    "import numpy as np\n",
    "\n",
    "# Data frames.\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot style.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Plot size.\n",
    "plt.rcParams['figure.figsize'] = [14, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new neural network.\n",
    "m = kr.models.Sequential()\n",
    "\n",
    "# Add a two neurons in a single layer.\n",
    "m.add(kr.layers.Dense(2, input_dim=1, activation=\"linear\"))\n",
    "\n",
    "# Add a single neuron in a single layer, initialised with weight 1 and bias 0.\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\", kernel_initializer=kr.initializers.Constant(value=1), bias_initializer=kr.initializers.Constant(value=0)))\n",
    "\n",
    "\n",
    "\n",
    "# Set the weight/bias of the two neurons.\n",
    "m.layers[0].set_weights([np.matrix([2.0, 3.0]), np.array([-5.0, -3.0])])\n",
    "\n",
    "# Compile the model.\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some input values.\n",
    "x = np.arange(-10.0, 10.1, 1.0)\n",
    "\n",
    "# Run each x value through the neural network.\n",
    "y = m.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-58.],\n",
       "       [-53.],\n",
       "       [-48.],\n",
       "       [-43.],\n",
       "       [-38.],\n",
       "       [-33.],\n",
       "       [-28.],\n",
       "       [-23.],\n",
       "       [-18.],\n",
       "       [-13.],\n",
       "       [ -8.],\n",
       "       [ -3.],\n",
       "       [  2.],\n",
       "       [  7.],\n",
       "       [ 12.],\n",
       "       [ 17.],\n",
       "       [ 22.],\n",
       "       [ 27.],\n",
       "       [ 32.],\n",
       "       [ 37.],\n",
       "       [ 42.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the outputs.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the values.\n",
    "plt.plot(x, y, 'k.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-58., -53., -48., -43., -38., -33., -28., -23., -18., -13.,  -8.,\n",
       "        -3.,   2.,   7.,  12.,  17.,  22.,  27.,  32.,  37.,  42.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the output using numpy arrays.\n",
    "neuron1 =  2.0 * x - 5.0\n",
    "neuron2 =  3.0 * x - 3.0\n",
    "neuron3 = neuron1 + neuron2\n",
    "neuron3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new neural network.\n",
    "m = kr.models.Sequential()\n",
    "\n",
    "# Add a single neuron in a single layer, initialised with weight 1 and bias 0, with sigmoid activation.\n",
    "m.add(kr.layers.Dense(1, input_dim=1, activation=\"sigmoid\", kernel_initializer=kr.initializers.Constant(value=1.0), bias_initializer=kr.initializers.Constant(value=0.0)))\n",
    "\n",
    "# Compile the model.\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some input values.\n",
    "x = np.arange(-10.0, 10.1, 1.0)\n",
    "\n",
    "# Run each x value through the neural network.\n",
    "y = m.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the values.\n",
    "plt.plot(x, y, 'k.');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From video 'Linear regression in Keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot style.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Plot size.\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear equation.\n",
    "f = lambda x: 3.0 * x + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "      <th>power</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.020045</td>\n",
       "      <td>184.060134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.367919</td>\n",
       "      <td>98.103756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.734396</td>\n",
       "      <td>138.203187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.381962</td>\n",
       "      <td>236.145885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.563087</td>\n",
       "      <td>20.689260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>24.775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.033731</td>\n",
       "      <td>181.101192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>24.850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.349975</td>\n",
       "      <td>17.049925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>24.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.155712</td>\n",
       "      <td>49.467135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>24.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.714248</td>\n",
       "      <td>162.142744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>25.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.304540</td>\n",
       "      <td>139.913620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speed  power          x           y\n",
       "0     0.000    0.0  61.020045  184.060134\n",
       "1     0.125    0.0  32.367919   98.103756\n",
       "2     0.150    0.0  45.734396  138.203187\n",
       "3     0.225    0.0  78.381962  236.145885\n",
       "4     0.275    0.0   6.563087   20.689260\n",
       "..      ...    ...        ...         ...\n",
       "495  24.775    0.0  60.033731  181.101192\n",
       "496  24.850    0.0   5.349975   17.049925\n",
       "497  24.875    0.0  16.155712   49.467135\n",
       "498  24.950    0.0  53.714248  162.142744\n",
       "499  25.000    0.0  46.304540  139.913620\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a training data frame with x and y values.\n",
    "# The x values are randomly selected between 0 and 100.\n",
    "# y_i is f(x_i)\n",
    "train = pd.read_csv(\"./misc/powerproduction.csv\")\n",
    "train['x'] = np.random.uniform(0.0, 100.0, 500)\n",
    "train['y'] = f(train['x'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "      <th>power</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.170862</td>\n",
       "      <td>241.512586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.533140</td>\n",
       "      <td>104.599419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.589464</td>\n",
       "      <td>260.768392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.403351</td>\n",
       "      <td>89.210054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.583922</td>\n",
       "      <td>32.751765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>24.775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.991996</td>\n",
       "      <td>75.975987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>24.850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.753750</td>\n",
       "      <td>159.261249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>24.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.679233</td>\n",
       "      <td>57.037699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>24.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.851460</td>\n",
       "      <td>246.554381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>25.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.480072</td>\n",
       "      <td>65.440216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speed  power          x           y\n",
       "0     0.000    0.0  80.170862  241.512586\n",
       "1     0.125    0.0  34.533140  104.599419\n",
       "2     0.150    0.0  86.589464  260.768392\n",
       "3     0.225    0.0  29.403351   89.210054\n",
       "4     0.275    0.0  10.583922   32.751765\n",
       "..      ...    ...        ...         ...\n",
       "495  24.775    0.0  24.991996   75.975987\n",
       "496  24.850    0.0  52.753750  159.261249\n",
       "497  24.875    0.0  18.679233   57.037699\n",
       "498  24.950    0.0  81.851460  246.554381\n",
       "499  25.000    0.0  21.480072   65.440216\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a corresponding test data frame.\n",
    "# It might be better to create one big data frame and randomly select test cases.\n",
    "test = train\n",
    "test['x'] = np.random.uniform(0.0, 100.0, 500)\n",
    "test['y'] = f(test['x'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network with one neuron.\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Dense(1, input_shape=(1,), activation=\"linear\", kernel_initializer='ones', bias_initializer='zeros'))\n",
    "model.compile('adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 12263.0995\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 11772.7778\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12172.0784\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 11833.2147\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11346.8293\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11407.5769\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11631.8872\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11162.4486\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11259.7434\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10863.5699\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11305.9288\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10856.7024\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - ETA: 0s - loss: 10837.542 - 0s 3ms/step - loss: 10309.8074\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10543.2814\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10240.1063\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9630.8316\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10527.4559\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9690.1237\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8821.5584\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9449.3454\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8817.9318\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8655.9983\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8888.8311\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9056.8531\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8192.0570\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8121.0016\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8022.2498\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7748.8170\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8191.9436\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7106.4188\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7707.6645\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7443.8593\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7371.3255\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7477.3176\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6712.6734\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7145.9067\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7261.0658\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6738.4836\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6429.7242\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6474.1848\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6068.1226\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6591.8009\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5721.6718\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5556.3157\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5912.6103\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5547.9844\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5584.8306\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5343.2110\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5342.4098\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5424.6814\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5074.8574\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5261.7592\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5085.2088\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4902.4635\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4754.0654\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4468.1789\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4577.2190\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4270.8435\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4303.7934\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4352.8478\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4172.3833\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4246.6999\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3875.9964\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3973.2159\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3780.1367\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3739.7874\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3619.6302\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3510.9987\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3612.3409\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3563.4886\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3351.3299\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3318.1685\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3259.3071\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3272.0022\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3131.9034\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2998.9696\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2926.0409\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2995.7471\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2789.9608\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2759.7334\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2478.4382\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2577.9446\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2487.3903\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2414.4606\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2414.5269\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2243.9116\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2337.9187\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2306.9762\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2095.7102\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2150.0298\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2043.6809\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2056.5492\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1940.1241\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2024.3459\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1838.2219\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1886.7183\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1709.9253\n",
      "Epoch 98/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 1792.5749\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1805.5455\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1597.1372\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1645.5886\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1615.2263\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1459.7443\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1468.1875\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1416.2794\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1385.6865\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1360.5044\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1345.2224\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1283.3618\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1332.2305\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1207.0906\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1132.7008\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1143.5272\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1090.6807\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1125.6178\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1059.9474\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1004.5180\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 969.6358\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 941.6690\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 869.4333\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 828.8973\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 923.2669\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 819.4903\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 840.2603\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 822.5899\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 775.2611\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 720.0937\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 675.6292\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 689.9703\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 712.6884\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 649.4608\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 603.5440\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 605.7243\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 589.1425\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 587.4331\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 560.7289\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 555.7634\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 501.5977\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 492.8028\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 515.1649\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 446.5094\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 458.0465\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 418.4041\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 444.1377\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 373.7888\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 390.8610\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 358.7972\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 356.0193\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 339.5502\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 354.1113\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 330.8937\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 305.7866\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 299.4466\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 271.8065\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 278.3695\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 260.5892\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.5348\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.5369\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.7446\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 227.8108\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 229.5795\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 198.1936\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 206.5463\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 176.3985\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 187.7268\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - ETA: 0s - loss: 178.398 - 0s 2ms/step - loss: 171.5646\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 169.5064\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 155.6991\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 148.8011\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 140.7336\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 134.5580\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 131.8111\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 126.9447\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 118.4193\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 110.0154\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 118.0708\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 106.7036\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 98.7609\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 92.1763\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 95.1449\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 90.5342\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 81.4258\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 85.3542\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 70.2379\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 71.6541\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 72.1132\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 65.9944\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 63.5148\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 59.3672\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 57.9587\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 51.7041\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.6365\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.6528\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.8896\n",
      "Epoch 195/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 43.7860\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40.3277\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.1494\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 34.8388\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.4609\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.0649\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.7249\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 30.2205\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 28.6692\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 25.3725\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24.8074\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 23.5913\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.9775\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 21.2852\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.9268\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.9341\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.6712\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.2294\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.5945\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13.4546\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.0614\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12.2129\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12.0312\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 11.2277\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.5273\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.0466\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.2417\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.9570\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.4153\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.3312\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.3135\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7389\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.5812\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.2048\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.4798\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.2816\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.2864\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.0688\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.0801\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.8094\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.6796\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.0420\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8699\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8321\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.7258\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.2443\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2932\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1344\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.9447\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9501\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6193\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6086\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4743\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3238\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2660\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2314\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1377\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0334\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9241\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.788 - 0s 3ms/step - loss: 0.9092\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8451\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8302\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7476\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7164\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6658\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6662\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5853\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5469\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4992\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4762\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4550\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4492\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4250\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4013\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4091\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3742\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3813\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3613\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3556\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3190\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3386\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3135\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3226\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2875\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2939\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2837\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2692\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2819\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2612\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2523\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2705\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2613\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2545\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2432\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2379\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2500\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2455\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2210\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2459\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2490\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2292\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2393\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2412\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2315\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2305\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2246\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2253\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2576\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2340\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2275\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2249\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2288\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2435\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2430\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2400\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2321\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2243\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2290\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2252\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2347\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2183\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2370\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2333\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2410\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2196\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2316\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2440\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2254\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2232\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2359\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2116\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2146\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2237\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2175\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2255\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2160\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2219\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2190\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.209 - 0s 3ms/step - loss: 0.2164\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2072\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2112\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2205\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2354\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2218\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2288\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2227\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2174\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2197\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2096\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2203\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2297\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2153\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2239\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2152\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2181\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2175\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2171\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2092\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2222\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2330\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2234\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2243\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2266\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2202\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2180\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2342\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2151\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2286\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2160\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2292\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2055\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2152\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2182\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2227\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2201\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2223\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2068\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2207\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2140\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2121\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2031\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2102\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2090\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2194\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2146\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1986\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2165\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2161\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2258\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2172\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2196\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2155\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2082\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2180\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1840\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2062\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2146\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2028\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2217\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2100\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1958\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2190\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2051\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2073\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2109\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2026\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2014\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2000\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2018\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1978\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2147\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2186\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2189\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2134\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1960\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2026\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1992\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2168\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1966\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1981\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2010\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1985\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2048\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1965\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1958\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2055\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1813\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1908\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2025\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2056\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1936\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1924\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2079\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1920\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1719\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1912\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2011\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1913\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1874\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1927\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1918\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2005\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1909\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2013\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1852\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1831\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1904\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1982\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2018\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1858\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1837\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1934\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1841\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1876\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1779\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2055\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1882\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1838\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1722\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1771\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1900\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1802\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1806\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1785\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1843\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1801\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1850\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1807\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1797\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1822\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1844\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1712\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1845\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1811\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1787\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1802\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1696\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1702\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1867\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1839\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1734\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1668\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1761\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1679\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1647\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1744\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c8ef68ea60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network on our training data.\n",
    "model.fit(train['x'], train['y'], epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
